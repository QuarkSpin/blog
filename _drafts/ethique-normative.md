---
layout: post
title: "Éthique Normative"
# date:   2020-11-20 16:08:00 +0200
categories: Philosophie Ethique
tags:
    - Philosophie morale
    - Éthique normative
excerpt: ... ...
image:
  path: /images/post-images/2020-11-20-ethique-normative/main.jpg
  thumbnail: /images/post-images/2020-11-20-ethique-normative/main-thumb-flat.jpg
  caption: " Photo par [Jordan Madrid](https://unsplash.com/@jordanmadrid)"
---

{% include wip %}

{% include toc %}

## Introduction

### Questions d'éthique

La société moderne se pose de nombreuses questions éthiques, notamment dans le cadre de la bioéthique et des nouvelles technologies.

Est-ce que les personnes vivant actuellement importent plus que les personnes à venir ? Peut-on, et si oui comment, trier les malades et blessés en cas de ressources limitées ? L'avortement est-il justifiable dans certaines circonstances ? Et l'euthanasie ? Peut-on modifier le génome humain pour soigner le cancer ? La justice doit-elle être punitive, réhabilitative ou réparatrice ? Vivre dans le monde "réel" plutôt que "virtuel" est-il une obligation éthique ? Qu'est ce qui peut ou non justfier une intervention militaire ? Sur quels critères se baser pour permettre ou interdire des comportements en société ? Quelles sont les problématiques autour des recherches sur l'embryon humain ? Doit-on présumer le consentement au don d'organe d'une personne décédée ? Quelles questions éthiques entourent la contraception, la reproduction et l'éducation sexuelle ? Quels rôles et règles de décision donner aux IA, par exemple dans le cas d'une voiture autonome (doit-elle tenter de sauver ses occupants ou les sacrifier pour sauver plus de vies) ? Etc, etc.

Je souhaite aborder toutes ces questions et d'autres dans des articles à venir, plus ou moins en profondeur selon les sujets. Mais avant toute chose, il me faut conduire une réflexion sérieuse sur l'*éthique normative*, nécessaire pour aborder des cas concrets avec rigueur.

### Dilemmes

Commençons par deux expériences de pensée.

Imaginez un aiguilleur d'une voie de train. Il peut décider de faire passer le train par la voie principale ou par une voie secondaire. Imaginez que cinq personnes soient coincées sur la voie principale et qu'une soit coincée sur la voie secondaire. Un train arrive et ses freins ont lâchés. L'aiguilleur peut alors :

1. Ne rien faire et laisser le train s'engager sur la voie principale. Le train tuera cinq personnes.
2. Aiguiller le train sur la voie secondaire. Le train tuera une personne.

Que devrait faire l'aiguilleur ? Quel est le choix le plus éthique ?

Il semble assez intuitif de privilégier la deuxième option afin de sauver le plus de vies.

![Dilemme du tramway]({{ site.baseurl }}/images/post-images/2020-11-20-ethique-normative/dilemme_tram.svg)

Imaginez maintenant un chirurgien, spécialiste des transplantations.

Pour l'expérience, considérons que  :

* Le taux de réussite du chirurgien est de 100%, les opréations se font sans risque.
* Le chirurgien n'a de comptes à rendre à personne, si ce n'est lui-même, personne n'est au courant de ses choix éthiques et il ne fait face à aucune conséquence juridique, économique, sociale, etc.
* Son service est "isolé", il ne peux pas demander de l'aide, transférer des patients, recevoir des organes d'une banque d'organes, etc.

![Chirurgien]({{ site.baseurl }}/images/post-images/2020-11-20-ethique-normative/chirurgien.jpg){: .medium-height}
*Photo du [National Cancer Institute](https://unsplash.com/@nci)*

Un jour un patient arrive pour une appendicite, une opération bénine. Le chirurgien l'endort et s'apprête à l'opérer quand cinq autres patients arrivent, chacun ayant un organe vital différent défaillant. Il se trouve que l'homme qui doit être anesthésié pour l'appendicite est compatible avec les cinq nouveaux patients, ses organes pourraient les sauver.

Le chirurgien a alors deux choix :

1. Soit il opère le premier patient et laisse mourrir les cinq autres
2. Soit il prélève les organes du premier patient sans son consentement, causant sa mort, et sauve les cinq autres

Que devrait faire le chirurgien ? Quel est le choix le plus éthique ?

Si comme dans le premier scénario, on souhaite sauver le plus grand nombre de vie, alors la seconde option est la bonne. Pourtant la choisiriez-vous ?

Le deux dilemmes précédents sont des expériences de pensée proposées, parmi d'autres, par la philosophe américaine Judith Jarvis Thomson notamment dans deux articles[^thomson_76] [^thomson_85] publiés en 1976 et 1985. Thomson a posé ses problèmes à un grand nombre de participants et recuilli les résultats.

Il est intéressant de noter que dans les deux scénarios que j'ai mentionné, à chaque fois on a le choix de faire un action qui soit hôte une vie pour en sauver cinq, soit l'inverse. Mais d'après ces études, l'imense majorité des gens choisist la deuxième option dans le premier cas (dévier le train) mais le première dans le second cas (ne pas prélever les organes).

Pourtant les deux cas sont similaires :

* *Ne pas dévier le train* correspond à *ne pas prélever d'organes* (5 morts, 1 vivant) : on laisse les choses se dérouler comme si on n'avait pas eu de solution alternative
* *Dévier le train* correspond à *prélever les organes* (5 vivants, 1mort) : on agit pour sauver le plus grand nombre, causant la mort d'une personne qui vivrait sans notre intervention

Déterminer comment choisir ce qui est éthique (ou *moral*, ces termes pouvant être confondus dans ce contexte[^britannica_morality_ethics]) de faire est justement le rôle de l'*éthique normative*, sujet de cet article.

### Différents types d'éthique

On distingue quatre catégories d'éthique :

* La *méta-éthique*, qui est d'ordre métaphysique, s'intéresse à la nature, à la portée et à la signification des termes liés au jugement moral.
* L'*éthique normative*, examine les standards, forme les théories et définit les critères qui permettent de formuler un jugement moral.
* L'*éthique appliquée*, applique les critères définis par l'éthique normative à des cas concrets.
* L'*éthique descriptive*, se contente d'étudier les croyances éthiques de différents groupes de personnes sans prétendre les juger.

Cet article s'intéresse donc en particulier à l'éthique normative, à ses différentes théories et aux critères qu'on peut en tirer.

### Mes objectifs

Mes objectifs à atteindre à la fin de la rédaction de cet article sont :

* Avoir une bonne compréhension des différentes théories majeurs de l'éthique normative
* Comprendre les limitations de ces théories dans certains cas limites
* Déterminer de manière approximative quelle à quelle théorie je souscris le plus en général et quand je souhaite faire intervenir les autres
* Trouver une série de principes pour bien aborder les futures questions éthiques que j'examinerai

## Dimension personnelle

Avant d'entrer dans le coeur du sujet, je voudrais aborder l'aspect des valeurs et leur impact.

### Relativisme, universalisme et réalisme

Il existe une discussion dans la sphère *méta-éthique* autour de l'universalité de l'éthique : est-elle propre à chaque individu et à chaque culture (c'est la position *relativiste*) ou est-elle universelle (c'est les positions *universalistes* et *réalistes*) ?

La plupart des gens comme des expert s'accordent à dire que l'éthique est généralement universelle, mais qu'il reste des parts de subjectivité notamment dans la hiérarchie des valeurs propre à chaque individu.

Ainsi l'éthique est *plutôt universelle* lorque le choix porte entre une valeur majoritairement considérée positive et une majoritairement considérée négative, et *plutôt relative* lorsqu'il s'agit d'un choix entre deux valeurs assez proches dans la hiérarchie de valeurs mais pas toujours classées dans le même ordre selon les individus.

### Valeurs personnelles

Il n'existe pas de définitions précises des "valeurs" éthiques ou morales. En général, on considère qu'il s'agit d'un concept, d'une idée, d'une action à laquelle on attribue de l'importance. Elles indiquent d'une manière prférencielle d'agir (honnêteté, indépendance, courage, etc.) ou d'état du monde (paix, liberté, sécurité, etc.).

Comme mentionné précédemment, les valeurs personnelles et leur importance relative pour chaque individu, influencent leurs choix éthiques.

Par exemple dans l'épisode 2 du podcast Axiome[^axiome_2], le philosophe Thibaut Giraud et le mathématicien Lê Nguyên Hoang répondent différemment à une même expérience de pensée.

En résumé, la question est la suivante : si vous en aviez le pouvoir, que choisirez-vous entre :

* Soit toute l'humanité se connecte à un monde virtuel, cesse d'explorer l'univers et d'acquérir de nouvelles connaissances pour toujours, mais toute souffrance (guerre, pauvreté, faim, maladie, solitude, etc.) est définitivement erradiquée et tout le monde est parfaitement heureux
* Soit l'humanité continue de vivre dans le monde réel, mais il y aura toujours beaucoup de souffrance

Le philosohpe a préréfé la deuxième option, accordant plus de valeur à la connaissance du monde réel qu'à l'erradication de la suffrauce et au bonheur. Le mathématicien a préféré l'inverse.

Le podcast en question (à partir de 22:20) :

{% include responsive-embed url="https://youtube.com/embed/__11zlc8Fdo?t=1340" ratio="16:9" %}

Quoi que serait notre choix dans cette situation, je ne pense pas que l'on puisse dire qu'un choix est *fondamentalement* meilleur que l'autre. La connaissance, la liberté, l'égalirté, le bonheur, sont toutes des valeurs importantes. Mais leur hiérarchisation dans un cas pratique relève souvent de la considération personnelle.

## Les théories de l'éthique normative

Dans cette partie je passe en revue les principales théories de l'éthique normative et leurs variantes. Je veux ensuite distinguer celles qui me semblent les plus pertinentes, comprendre leurs limites et choisir une ou plusieurs variantes de ces théories pour aborder les futures questions concrètes.

Il existe historiquement trois grandes théories d'éthique normative :

* *L'éthique de la vertu* : elle met l'accent sur des "vertus", des traits positifs d'une personne. Cette théorie considère la personne faisant l'action plutôt que l'action elle-même.
* *Le déontologisme* : il considère qu'une action est éthique si elle suit des règles, droits et devoirs absolus.
* *Le conséquentialisme* : il considère une action éthique en fonction de ses conséquences prévisibles.

L'éthique de la vertu est la plus ancienne théorie d'éthique normative, formulée par Aristote durant l'antiquité. Elle est aujourd'hui majoritairement obsolète et seuls quelques philosophes la défendent encore. Les critiques le plus souvent formulées à son encontre sont notamment le fait qu'elle ne juge pas de la moralité des actions et ne dit pas ce qu'on deevrait faire mais ce qu'on devrait être.

De fait, les deux théories d'éthique normatives largement représentées aujourd'hui sont le déontologisme et le conséquentialisme et leurs différentes variantes. Je vais donc me concentrer sur celles-ci, d'autant que je les trouve plus pertinentes.

### Déontologisme

Voici ce qu'en dit l'Encyclopédie de Philosophie de Stanford[^plato_deo] :

> Le *déontologisme* soutient que les actions ne peuvent pas être justifiées par leurs effets – que, quelles que soient leurs conséquences, certaines actions sont moralement interdites. Ce qui fait une bonne action, c'est sa conformité à une norme morale. On dit que le *juste* est plus important que le *bon*. Si une action n'est pas en accord avec la règle, elle ne peut être entreprise, quel que soit le bien qu'elle pourrait produire.

Et l'encyclopédie Britannica[^brita_deo] :

> Dans l'*éthique déontologique,* une action est considérée comme moralement bonne en raison de certaines caractéristiques de l'action elle-même, non parce que le produit de l'action est bon.

Le déontologisme a été introduit au 18<sup>è</sup> siècle par le philosophe allemand Emmanuel Kant. Il en existe aujourd'hui deux variantes principales.

#### L'impératif catégorique

Théorisé par Emmanuel Kant, il affirme qu'il existe des impératifs hypothétiques ("pour atteindre A, fais X") et d'autres catégoriques ("fais X") et donc absolus. Suivre l'éthique de l'impératif catégorique consiste en l'accomplissement du *devoir*, universel, définis par des impératifs moraux catégoriques.

Le contenu même de ce devoir (la liste des impératifs catégoriques moraux) n'est pas précisé, ce qui est certain est sa *forme* (absolue, non dépendant des conséquences).

#### Le contractualisme et le droit naturel

Théorisé notamment par John Locke, il dérive de l'impératif catégorique mais affirme que les imparatifs sont définis par l'*état de nature* qui est, selon Locke, "un état dans lequel les hommes se trouvent en tant qu'hommes et non pas en tant que membres d'une société".

Ainsi il y aurait trois droits naturels :

* La vie : chacun a le droit de vivre
* La liberté : chacun a le droit de faire ce qu'il veut tant que cela ne contredit le premier droit de personne
* La propriété : chacun a le droit de posséder ce qu'il crée ou obtient par le don ou l'échange, tant que cela ne contredit les premiers ou second droits de personne

D'après cette théorie, agir moralement c'est respecter ces règles et n'en ériger aucune autre.

#### Déontologisme moderne

Aujourd'hui et à l'exception des courants libertariens (notamment aux États-Unis), ce sont des dérivés de l'impératif catégorique de Kant qui sont largement majoritaires dans le déontologisme, notamment car non restreints par l'*état de nature* de Locke.

Cependant quelles règles doivent êtres des absolus inviolables doit toujours être précisé. Il existe différentes approches pour les définir (livre sacré, accord mutuel, vote majoritaire, etc.).

#### Limites

Le déontologisme a plusieurs limites, la principale étant bien sûr qu'une action considérée comme morale peut avoir des conséquences dramatiques. Il est souvent avancé que la moralité d'une action dépend en grande partie du contexte (c'est l'idée du conséquentialisme qu'on verra jusye après).

Un exemple fameux est celui de la règle "dis la vérité".

* Si cette règle n'est pas un impératif moral, alors tout le monde est libre de mentir quand il veut.
* Si cette règle est un impératif moral, alors le mensonge sera toujours immoral quelle que soit la situation.

Imagonons maintenant que, durant la Seconde Guerre Mondiale, un homme cache des juifs chez lui. Un SS toque à la porte et lui demande "y a-t-il des juifs chez-vous". Si l'homme répond non, le SS partira. S'il répond oui il tuera les juifs.

Si on suit le déontologisme et que l'une des règles est "dis la vérité", alors si l'homme ne le fait pas il aura commis une action immorale. Si, pour éviter cette situation, on décide de ne pas ajouter pas cette règle aux impératifs, alors un mensonge ne pourrait jamais être immoral en soi.

Le même problème apparait avec la règle "ne tue pas" :

* Si cette règle n'est pas un impératif moral, alors tout le monde peut tuer à sa guise.
* Si cette règle est un impératif moral, alors tuer un homme sur le point de comettre un attentat n'est pas moral.

Si on souhaite ajouter une condition, par exemple "ne tue pas, sauf si la personne est sur le point de comettre un meurtre", alors on sort du cadre du déontologisme pour entrer dans le conséquentialisme.

### Conséquentialisme

Voici ce qu'en dit l'Encyclopédie de Philosophie de Stanford[^plato_con] :

> Le conséquentialisme est simplement l'idée que les propriétés normatives ne dépendent que des conséquences. La question de savoir si une action est moralement juste dépend uniquement des conséquences de celle-ci ou de quelque chose lié à cette action, comme l'intention.

Le conséquentialisme, sous sa forme moderne, a été introduit au 18<sup>è</sup> siècle par Jeremy Bentham et développé au 19<sup>è</sup> siècle par John Stuart Mill. Il existe deux variantes principales.

#### Égoïsme

Cette variante fais techniquement partie du conséquentialisme, même si on la considère rarement. Il s'agit de considérer comme éthique ce qui maximise l'intérêt pour soi ou pour un groupe de personne exclusif auquel on s'identifie. Elle n'est pas vraiment intéressante.

#### Utilitarisme

L'utilitarisme est la théorie d'éthique normative la plus récente maus aussi la plus développée. Elle contient des variations subtiles mais, en résumé, elle évalue la moralité des actes en fonctions de leurs conséquences prévisibles selon le critère de maximisation du bonnheur, du bien-être, de la connaissance, etc. et de minimisation du malheur, de la souffrance, de l'ignorance, etc. Il s'agit de prendre en compre tous les impacts, pas seulement ceux qui affectent une seule personne ou un seul groupe.

Comme le dit l'Encyclopédie de Philosophie de Stanford[^plato_con] :

> Une action est moralement juste si, et seulement si elle maximise le bien, c'est-à-dire si, et seulement si le montant total du bien pour tous moins le montant total du mal pour tous est supérieur à ce montant net pour tout acte incompatible dont on dispose à cette occasion.

En gros, c'est comme si on associait à chaque action un score de moralité égal aux conséquences positives moins les conséquences négatives. L'action moralement juste est celle, parmis celles qui nous sont possibles, qui maximise ce score (qui produit le plus de bien et le moins de mal).

De même, on voit aussi que l'action morale à choisir dépend des autres actions possibles.

Par exemple si on a le choix entre sauver une ou deux personnes (sans avoir plus d'informations sur qui sont ces personnes), l'action morale est d'en sauver deux. Si maintenant on a le choix d'en sauver une, deux ou trois, l'action morale n'est plus d'en sauver deux mais trois.

Comme pour le déontologisme, ce qu'il reste à déterminer sont les critères pour évaluer les conséquences des actions.

Dans sa forme originale, l'utilitarisme proposait d'évaluer les actions selon deux critères :

* Maximisation du bonheur
* Minimisation de la souffrance

De nombreux autres critères s'ajoutent souvent, d'importance égale ou non, comme la connaissance, la prospérité, etc.

Il existe différentes manières de considérer les conséquences des actes, en intégrant ou non la motivation de la personne, en distinguant conséquences désirées/prévues/réelles, en considérant ou non que diminuer la souffrance d'une personne qui souffre beaucoup vaut mieux que de diminuer autant la souffrance d'une qui souffre peu, en incluant ou excluant la personne qui commet l'action de l'évaluation des conséquences, etc.

D'une manière général, l'utilitarisme classique suit les règles suivantes :

* On ne considère pas les motivations de la personne
* On considère les conséquences telles qu'elles étaient prévisibles par la personne qui a fait le choix au moment où elle l'a fait (par opposition aux conséquences réelles telles qu'elle ont eu lieu, ou prévisibles)

Dans la suite je ne considèrerai que l'utilitarisme comme représentant du conséquentialisme (l'égoïsme me semblant non pertinent).

#### Limites

L'utilitarisme a plusieurs limites, la principale étant que s'il se limite aux critères vagues du bonheur et de la souffrance, il peut arriver à justifier des actions que la majorité des gens considèrent imorales, comme par exemple fair souffrir une minorité de la population si cela augmente le bien du plus grand nombre.

Pour parer à celà, certains philosophes utilitaristes proposent d'ajouter des critères comme la minimisation des écarts de bonheur, ou de considérer les mesures (bonheur, souffrance, etc.) comme relatives (en pourcentage plutôt qu'en valeur absolue).

Un autre problème est qu'il n'y a aucune règle intransgressable en tant que telle pour l'utilitarisme. Par exemple dans le problème du chirurgien (voir l'introduction), si l'utilitarisme n'inclut pas le consentement des individus dans ses critères, alors prélever les organes est le choix moral.

### Résumé

| | Déontologisme | Conséquentialisme / Utilitarisme |
|---|---|---|
| Principe | La valeur éthique d'une action peut être déterminée en elle-même selon quelle suit ou non certaines règles absolues | La valeur éthique d'une action ne peut être déterminée qu'en examinant ses conséquences prévisibles |
| Accent | Action en elle-même | Conséquences prévisibles de l'action |

### Double process

La recherche en neurosciences suggère[^dual_processing] que les individus utilisent un mélange de déontologisme et d'utilitarisme lorsq'ils font des choix moraux. Si le choix est impulsif et émotionnel, il sera un peu plus basée sur le déontologisme. A l'inverse, si le choix est réfléchi, il sera un peu plus basé sur l'utilitarisme.

Ces propensions varient également en fonction des préférences des individus[^deo_uti]. Aucun individu n'est purement déontologue ni purement utilitariste.

## Comparaison des principales théories d'éthique normative

Afin de mieux comprendre les distinctions et les limites du déontologisme et de l'utilitarisme, je vais essayer de voir comment ces deux théories diffèrent dans l'approche de plusieurs exemples.

### Problèmes de Conway et Gawronski

En 2013 les psychologues américains Paul Conway et Bertram Gawronski ont mené des recherches[^deo_uti] pour étudier les inclinaisons morales déontologiques et utilitaristes chez des groupes de sujets. Ils ont, entre autres, rédigé des dilemmes moraux où les deux approches donnent des réponses opposées.

Le but de ces expériences et de mettre en évidences les points de divergeance des deux approches. Voici quelques-uns de ces dilemmes. La réponse donnée par la grande majorité des déontologues sont indiqués dans la colonne D et ceelle des utilitariste dans la colonne U.

NB : les scénarios restreignent volontairement les options (par exemple tuer ou de laisser vivre). Aucune autre action n'est possible. C'est le but de l'expérience : empêcher les situations "de compromis" pour mieux étudier les différences entre les deux approches.

#### Voyage temporel

| Énoncé | D | U |
|---|---|---|
| Vous remontez dans le temps en 1920 et avez l'occasion d'éliminer George Brackman. Si vous le laissez vivre, il va dans quelques années enlever une jeune fille et la restituer quelques jours plus tard contre rançon sans lui avoir fait de mal. Le tuez-vous ? | ❌ | ❌ |
| Vous remontez dans le temps en 1920 et avez l'occasion d'éliminer Adolf Hitler. Si vous le laissez vivre, il va dans quelques années provoquer la mort de millions de personnes. Le tuez-vous ? | ❌ | ✔️ |

Le déontologisme ne justifie pas de donner la mort à un innocent (au moment des faits), même pour sauver des vies.

Le conséquentialisme justifie la mort d'un innocent pour en sauver un plus grand nombre, mais pas pour empêcher un kidnaping qui se termine bien.

#### Train fou

| Énoncé | D | U |
|---|---|---|
| Un train arrive à grande vitesse sur une voie où se trouvent 5 personnes. Vous pouvez le dévier sur une voie de secours où se trouve une personne. Queles que soient la voie empruntée les personnes dessus mourront. Déviez-vous le train ? | ❌ | ✔️ |

Le déontologisme ne justifie pas de donner la mort à un innocent, même pour sauver des vies.

Le conséquentialisme choisit la solution qui épargne le plus de vies.

#### Prostitution

| Énoncé | D | U |
|---|---|---|
| Vous avez deux enfants en bas âge. Vous êtes pauvre. Sans entrée d'argent ils n'auront pas de cadeau ce Noël. Vous avez la possibilité de vous prostituer pour gagner une grosse somme d'argent. Le faites-vous ? | ❌ | ❌ |
| Vous avez deux enfants en bas âge. Vous êtes pauvre. Sans entrée d'argent ils mourront de faim d'ici deux jous. Vous avez la possibilité de vous prostituer pour gagner une grosse somme d'argent. Le faites-vous ? | ❌ | ✔️ |

Le déontologisme ne justifie pas la transgresion d'une valeur morale.

Le conséquentialisme justifie la transgresion d'une valeur morale pour sauver des vies.

#### Terroriste

| Énoncé | D | U |
|---|---|---|
| Vous interrogez un terroriste qui connait l'emplacement d'une non armée qui doit exploser dans un endroit désert d'ici 24 heures, détruisant une maison inhabitée. Il refuse de parler. Si vous utilisez la torture il vous révèlera l'emplacement, sinon il ne parlera pas. Utilisez-vous la torture ? | ❌ | ❌ |
| Vous interrogez un terroriste qui connait l'emplacement d'une bombe armée qui doit exploser en ville d'ici 24 heures tuant des dizaines de personnes. Il refuse de parler. Si vous utilisez la torture il vous révèlera l'emplacement, sinon il ne parlera pas. Utilisez-vous la torture ? | ❌ | ✔️ |

Le déontologisme ne justifie pas la transgresion d'une valeur morale.

Le conséquentialisme justifie la transgresion d'une valeur morale pour sauver des vies.

### Jusqu'où serez-vous utilitariste ?

Le philosophe Thibaut Giraud (alias *Monsieur Phi* sur YouTube), explique que la plupart des gens sont utilitaristes en première approche dans la plupart des situations courantes, mais que très peu de gens sont "utilitaristes jusqu'au bout". En effet lorsque la situation est simple, qu'il n'y a pas vraiment de dilemme (par exemple dévier un train sur une voie où il n'y a personne), la plupart des gens considèrent les conséquences de l'action pour prendre une décision. Mais il arrive un moment où la plupart cesse d'être utilitariste, considérant alors certains principes comme plus importants que les conséquences des actions.

M. Giraud a conçu une série de scénarios successifs, chacun variant très légèrement du précédent. La plupart des gens font un choix totalement utilitariste au premier et totalement déontologiste au dernier. Mais tout le monde ne passe pas d'une approche à l'autre au même moment.

Essayez de répondre honnêtement à chacun des scénarios suivants et voyez au quel vous devenez déontologue (normalement vous devriez répondre au premier en étant utilitariste).

#### Le contexte

TODO

#### Scénario 1

TODO

### TODO exemples voiture IA


## TODO

A placer quelquepart :

### Général vs personnel / Éthique et loi

Distinction entre ce qui est ou non éthique de manière généralisable à la société et ce qui relève de mes valeurs personnelles que je n'ai pas à imposer à la société (par exemple sous forme de loi). Distinction entre valeurs personnelles et générales.

<!-- Références -->

[^thomson_76]: Thomson, J. J., & The Hegeler Institute. (1976). *Killing, Letting Die, and the Trolley Problem* Monist, 59(2), 204‑217. <https://doi.org/10.5840/monist197659224>

[^thomson_85]: Thomson, J. J. (1985). *The Trolley Problem*. The Yale Law Journal, 94(6), 1395. <https://doi.org/10.2307/796133>

[^britannica_morality_ethics]: Grannan, C. (s. d.). *What's the Difference Between Morality and Ethics?* Encyclopedia Britannica. Consulté le 20 novembre 2020, à l'adresse <https://www.britannica.com/story/whats-the-difference-between-morality-and-ethics>

[^axiome_2]: Axiome. (2017, 25 août). *Optimisme probabiliste \| Axiome 2* [Vidéo]. YouTube. <https://www.youtube.com/watch?v=__11zlc8Fdo>

[^plato_deo]: Alexander, L., & Moore, M. (2020a). Deontological ethics. In E. N. Zalta (Éd.), *The Stanford Encyclopedia of Philosophy* (Winter 2020). Metaphysics Research Lab, Stanford University. <https://plato.stanford.edu/archives/win2020/entries/ethics-deontological/>

[^brita_deo]: The Editors of Encyclopaedia Britannica. (2020). Deontological ethics. In *Encyclopædia Britannica*. <https://www.britannica.com/topic/deontological-ethics>

[^plato_con]: Sinnott-Armstrong, W. (2019). Consequentialism. In E. N. Zalta (Éd.), *The Stanford Encyclopedia of Philosophy* (Summer 2019). Metaphysics Research Lab, Stanford University. <https://plato.stanford.edu/archives/sum2019/entries/consequentialism/>

[^dual_processing]: Greene, J. D. (2014). *Beyond Point-and-Shoot Morality : Why Cognitive (Neuro)Science Matters for Ethics*. Ethics, 124(4), 695‑726. <https://doi.org/10.1086/675875>

[^deo_uti]: Conway, P., & Gawronski, B. (2013). *Deontological and utilitarian inclinations in moral decision making : A process dissociation approach*. Journal of Personality and Social Psychology, 104(2), 216‑235. <https://doi.org/10.1037/a0031021>
